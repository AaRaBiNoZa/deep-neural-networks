{"cells":[{"cell_type":"markdown","metadata":{"id":"1LRuv3lwLLmV"},"source":["Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n","\n","In this exercise, we are going to implement a [UNet-like](https://arxiv.org/pdf/1505.04597.pdf) architecture for the semantic segmentation task. \n","The model is trained on the [Pascal VOC](https://paperswithcode.github.io/torchbench/pascalvoc/) dataset.\n","\n","Tasks:\n","\n","    1. Implement the missing pieces in the code.\n","\n","    2. Check that the given implementation reaches 68% test accuracy after a few epochs."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"QfIXmJ-dRXfE","executionInfo":{"status":"ok","timestamp":1669734166670,"user_tz":-60,"elapsed":8,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.transforms.functional import InterpolationMode\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"FxGS_WsORXfF","executionInfo":{"status":"ok","timestamp":1669734166671,"user_tz":-60,"elapsed":8,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["class UNetConvolutionStack(nn.Module):\n","    def __init__(self, in_channel, out_channel):\n","        super(UNetConvolutionStack, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channel),\n","            nn.LeakyReLU(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lyN2g-yQRXfG","executionInfo":{"status":"ok","timestamp":1669734166671,"user_tz":-60,"elapsed":7,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["class EncoderStack(nn.Module):\n","    def __init__(self, in_channel, out_channel, first_layer=False):\n","        super(EncoderStack, self).__init__()\n","        if first_layer:\n","            self.down = nn.Sequential(\n","                UNetConvolutionStack(in_channel, out_channel),\n","                UNetConvolutionStack(out_channel, out_channel),\n","            )\n","        else:\n","            self.down = nn.Sequential(\n","                nn.MaxPool2d((2, 2)),\n","                UNetConvolutionStack(in_channel, out_channel),\n","                UNetConvolutionStack(out_channel, out_channel),\n","            )\n","\n","    def forward(self, x):\n","        x = self.down(x)\n","        return x\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dp2-OwXORXfG","executionInfo":{"status":"ok","timestamp":1669734166672,"user_tz":-60,"elapsed":7,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["class DecoderStack(nn.Module):\n","    def __init__(self, in_channel, out_channel):\n","        super(DecoderStack, self).__init__()\n","        self.upsample = nn.ConvTranspose2d(\n","            in_channel, in_channel, 2, stride=2\n","        )\n","        self.up = nn.Sequential(\n","            UNetConvolutionStack(in_channel + out_channel, out_channel),\n","            UNetConvolutionStack(out_channel, out_channel),\n","        )\n","\n","    def forward(self, x, y):\n","        # TODO: implement skipconnections.\n","        # hint: x is the output of previous decoder layer,\n","        # y is the output of corresponding encoder layer.\n","        # Based on the arguments of the constructor,\n","        # how should x and y be combined?\n","        x = self.upsample(x)\n","        x_shp = x.size()\n","        x = self.up(torch.cat((y, x), 1))\n","        return x\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RBPeqMNSRXfG","executionInfo":{"status":"ok","timestamp":1669734166672,"user_tz":-60,"elapsed":6,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, encoder_channels, decoder_channels, num_classes):\n","        super(UNet, self).__init__()\n","        self.encoder = nn.ModuleList()\n","        self.decoder = nn.ModuleList()\n","        self.conv = nn.Conv2d(\n","            decoder_channels[-1], num_classes, kernel_size=3, padding=1\n","        )\n","\n","        encoder_sizes = zip(\n","            range(len(encoder_channels)), encoder_channels, encoder_channels[1:]\n","        )\n","        for idx, in_size, out_size in encoder_sizes:\n","            if idx > 0:\n","                self.encoder.append(EncoderStack(in_size, out_size))\n","            else:\n","                self.encoder.append(EncoderStack(in_size, out_size, first_layer=True))\n","\n","        decoder_sizes = zip(decoder_channels, decoder_channels[1:])\n","        for in_size, out_size in decoder_sizes:\n","            self.decoder.append(DecoderStack(in_size, out_size))\n","\n","    def forward(self, x):\n","        # TODO: implement UNet's forward pass.\n","        # hint: Remeber to store outputs of subsequent\n","        # encoder layers to use as input to decoer layers!\n","        # Do not forget about the final convolution.\n","        enc_outputs = []\n","        for enc_layer in self.encoder[:-1]:\n","          x = enc_layer(x)\n","          enc_outputs.append(x)\n","        x = self.encoder[-1](x)\n","        # print(x.size())\n","\n","        for dec_layer in self.decoder:\n","          x = dec_layer(x, enc_outputs.pop())\n","        \n","        return self.conv(x)\n","          \n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5AKH3oUqRXfH","executionInfo":{"status":"ok","timestamp":1669734167243,"user_tz":-60,"elapsed":577,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["x = []\n","def train(model, device, train_loader, optimizer, epoch, log_interval):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        x.append(target)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print(\n","                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n","                    epoch,\n","                    batch_idx * len(data),\n","                    len(train_loader.dataset),\n","                    100.0 * batch_idx / len(train_loader),\n","                    loss.item(),\n","                )\n","            )\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(\n","                output, target, reduction=\"sum\"\n","            ).item()  # sum up batch loss\n","            pred = output.argmax(\n","                dim=1, keepdim=True\n","            )  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    _, _, image_width, image_height = data.size()\n","    test_loss /= len(test_loader.dataset) * image_width * image_height\n","\n","    print(\n","        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n","            test_loss,\n","            correct,\n","            (len(test_loader.dataset) * image_width * image_height),\n","            100.0 * correct / (len(test_loader.dataset) * image_width * image_height),\n","        )\n","    )\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Ed1Rwhv-RXfH","executionInfo":{"status":"ok","timestamp":1669734167244,"user_tz":-60,"elapsed":13,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["batch_size = 128\n","test_batch_size = 1000\n","epochs = 5\n","lr = 1e-2\n","use_cuda = True\n","seed = 1\n","log_interval = 10\n","\n","imagenet_mean = [0.485, 0.456, 0.406]\n","imagenet_std = [0.229, 0.224, 0.225]\n","num_classes = 22\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Ht3SPPVlRXfH","executionInfo":{"status":"ok","timestamp":1669734167244,"user_tz":-60,"elapsed":12,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["use_cuda = use_cuda and torch.cuda.is_available()\n","\n","torch.manual_seed(seed)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","train_kwargs = {\"batch_size\": batch_size}\n","test_kwargs = {\"batch_size\": test_batch_size}\n","if use_cuda:\n","    cuda_kwargs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n","    train_kwargs.update(cuda_kwargs)\n","    test_kwargs.update(cuda_kwargs)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"dD85qSzwRXfI","executionInfo":{"status":"ok","timestamp":1669734167245,"user_tz":-60,"elapsed":13,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["def replace_tensor_value_(tensor, a, b):\n","    tensor[tensor == a] = b\n","    return tensor\n","\n","\n","input_resize = transforms.Resize((224, 224))\n","input_transform = transforms.Compose(\n","    [\n","        input_resize,\n","        transforms.ToTensor(),\n","        transforms.Normalize(imagenet_mean, imagenet_std),\n","    ]\n",")\n","\n","target_resize = transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST)\n","target_transform = transforms.Compose(\n","    [\n","        target_resize,\n","        transforms.PILToTensor(),\n","        transforms.Lambda(\n","            lambda x: replace_tensor_value_(x.squeeze(0).long(), 255, 21)\n","        ),\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"y7r9wpzeRXfI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669734205756,"user_tz":-60,"elapsed":38524,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}},"outputId":"adbfd669-3be0-4813-a325-cd13c7db945b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: ../data/VOCtrainval_11-May-2012.tar\n","Extracting ../data/VOCtrainval_11-May-2012.tar to ../data\n","Using downloaded and verified file: ../data/VOCtrainval_11-May-2012.tar\n","Extracting ../data/VOCtrainval_11-May-2012.tar to ../data\n"]}],"source":["dataset1 = datasets.VOCSegmentation(\n","    \"../data\",\n","    year=\"2012\",\n","    image_set=\"train\",\n","    download=True,\n","    transform=input_transform,\n","    target_transform=target_transform,\n",")\n","dataset2 = datasets.VOCSegmentation(\n","    \"../data\",\n","    year=\"2012\",\n","    image_set=\"val\",\n","    download=True,\n","    transform=input_transform,\n","    target_transform=target_transform,\n",")\n","\n","train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n","test_loader = torch.utils.data.DataLoader(dataset2, **train_kwargs)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"C1KtqXIPRXfJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669734330899,"user_tz":-60,"elapsed":125161,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}},"outputId":"3a4b9303-6096-4d6f-cb88-024c493a47f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/1464 (0%)]\tLoss: -0.059875\n","Train Epoch: 1 [1280/1464 (83%)]\tLoss: -4.201830\n","\n","Test set: Average loss: -3.5542, Accuracy: 4390021/72705024 (6%)\n","\n","Train Epoch: 2 [0/1464 (0%)]\tLoss: -5.204236\n","Train Epoch: 2 [1280/1464 (83%)]\tLoss: -11.492110\n","\n","Test set: Average loss: -11.3193, Accuracy: 24155886/72705024 (33%)\n","\n","Train Epoch: 3 [0/1464 (0%)]\tLoss: -12.972711\n","Train Epoch: 3 [1280/1464 (83%)]\tLoss: -22.082550\n","\n","Test set: Average loss: -27.5668, Accuracy: 21447348/72705024 (29%)\n","\n","Train Epoch: 4 [0/1464 (0%)]\tLoss: -24.231581\n","Train Epoch: 4 [1280/1464 (83%)]\tLoss: -36.817802\n","\n","Test set: Average loss: -38.5957, Accuracy: 49996455/72705024 (69%)\n","\n","Train Epoch: 5 [0/1464 (0%)]\tLoss: -39.772652\n","Train Epoch: 5 [1280/1464 (83%)]\tLoss: -57.504986\n","\n","Test set: Average loss: -80.2750, Accuracy: 50019174/72705024 (69%)\n","\n"]}],"source":["model = UNet(\n","    encoder_channels=[3, 8, 16, 32],\n","    decoder_channels=[32, 16, 8],\n","    num_classes=num_classes,\n",").to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","for epoch in range(1, epochs + 1):\n","    train(model, device, train_loader, optimizer, epoch, log_interval)\n","    test(model, device, test_loader)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"GifpCp-rRXfJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669734330900,"user_tz":-60,"elapsed":24,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}},"outputId":"19127bc0-2dd8-463b-974a-1cec31416655"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 224, 224])"]},"metadata":{},"execution_count":12}],"source":["x[0].size()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Y2Aa03GTRXfJ","executionInfo":{"status":"ok","timestamp":1669734330900,"user_tz":-60,"elapsed":21,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}}},"outputs":[],"source":["y = x[0]\n","k = replace_tensor_value_(y.squeeze(0).long(), 255, 21)"]},{"cell_type":"code","source":["k.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZgVmxUqkkIN","executionInfo":{"status":"ok","timestamp":1669734330901,"user_tz":-60,"elapsed":21,"user":{"displayName":"Adam Al-Hosam","userId":"09700474471122457475"}},"outputId":"7c5c8a15-db86-471e-9550-6e5aaeb3aec8"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 224, 224])"]},"metadata":{},"execution_count":14}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/mim-uw/dnn-2022-23/blob/master/released/DNN-Lab-7-UNet-in-Pytorch-student-version.ipynb","timestamp":1669671470792}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"6fa2fa4f4d9d3d9ca73eb3739cc0e85a72773041ed8c7376d5dc2c41e6946bf8"}}},"nbformat":4,"nbformat_minor":0}